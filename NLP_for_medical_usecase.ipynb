{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Drug Discovery and Development:** NLP can analyze vast amounts of biomedical literature and clinical trial data to identify potential drug targets, predict adverse drug reactions, and accelerate the drug discovery process."
      ],
      "metadata": {
        "id": "qsn8o0xKqc7o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkOPzQM3VOTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "319eQMKKprED",
        "outputId": "d2829558-67af-4437-84bd-af49ccf91c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample biomedical text data\n",
        "biomedical_text = \"\"\"\n",
        "Clinicians often suspect that a treatment effect can vary across individuals.\n",
        "However, they usually lack \"evidence-based\" guidance regarding potential heterogeneity of treatment effects (HTE).\n",
        "Potentially actionable HTE is rarely discovered in clinical trials and is widely believed (or rationalized) by researchers to be rare.\n",
        "Conventional statistical methods to test for possible HTE are extremely conservative and tend to reinforce this belief.\n",
        "In truth, though, there is no realistic way to know whether a common, or average, effect estimated from a clinical trial is relevant for all, or even most, patients.\n",
        "This absence of evidence, misinterpreted as evidence of absence, may be resulting in sub-optimal treatment for many individuals.\n",
        "We first summarize the historical context in which current statistical methods for randomized controlled trials (RCTs) were developed,\n",
        "focusing on the conceptual and technical limitations that shaped, and restricted, these methods. In particular,\n",
        "we explain how the common-effect assumption came to be virtually unchallenged.\n",
        "Second, we propose a simple graphical method for exploratory data analysis that can provide useful visual evidence of possible HTE.\n",
        "The basic approach is to display the complete distribution of outcome data rather than relying uncritically on simple summary statistics.\n",
        "Modern graphical methods, unavailable when statistical methods were initially formulated a century ago, now render fine-grained interrogation of the data feasible.\n",
        "We propose comparing observed treatment-group data to \"pseudo data\" engineered to mimic that which would be expected under a particular HTE model, such as the common-effect model.\n",
        "A clear discrepancy between the distributions of the common-effect pseudo data and the actual treatment-effect data provides prima facie evidence of HTE to motivate additional confirmatory investigation.\n",
        "Artificial data are used to illustrate implications of ignoring heterogeneity in practice and how the graphical method can be useful.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenization and preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [wordnet_lemmatizer.lemmatize(word) for word in tokens if word.isalnum()]\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "preprocessed_text = preprocess_text(biomedical_text)\n",
        "\n",
        "# Counting word frequencies\n",
        "word_freq = Counter(preprocessed_text)\n",
        "\n",
        "# Displaying the most common words\n",
        "print(\"Most common words in the text:\")\n",
        "for word, freq in word_freq.most_common(10):\n",
        "    print(f\"{word}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ArbfJnp0dL",
        "outputId": "90e13838-59a8-46a0-e097-129562a611f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common words in the text:\n",
            "data: 8\n",
            "method: 7\n",
            "hte: 6\n",
            "evidence: 4\n",
            "treatment: 3\n",
            "effect: 3\n",
            "trial: 3\n",
            "statistical: 3\n",
            "graphical: 3\n",
            "individual: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install summa\n",
        "from summa import summarizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wSoZ6pyp1bU",
        "outputId": "8cf5aef4-3325-432c-918e-df00aee6150d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting summa\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from summa) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy>=0.19->summa) (1.25.2)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54386 sha256=2d69021dfd0bc5e03a257b56d222c9b1f7a6a865c28d67ad3c3fb1de8a7fee72\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/ca/c5/4958614cfba88ed6ceb7cb5a849f9f89f9ac49971616bc919f\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the text using TextRank\n",
        "summary = summarizer.summarize(biomedical_text, ratio=0.2)\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKOIgMVmp4dH",
        "outputId": "b7a56fe5-f179-43bc-fd4e-906636ce130b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Second, we propose a simple graphical method for exploratory data analysis that can provide useful visual evidence of possible HTE.\n",
            "We propose comparing observed treatment-group data to \"pseudo data\" engineered to mimic that which would be expected under a particular HTE model, such as the common-effect model.\n",
            "A clear discrepancy between the distributions of the common-effect pseudo data and the actual treatment-effect data provides prima facie evidence of HTE to motivate additional confirmatory investigation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Atx99YA9qH6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}